{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae0c669-e177-4c86-9b9e-aa0f11902d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "CUDA_VISIBLE = '5'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00975a82-ca8c-4f67-bfa8-3c4771b80039",
   "metadata": {},
   "source": [
    "### Training params, you descriptions allows to not make cli and use notebook so I used it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b37a23-646f-45b2-ac8b-7dbb3dc507e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vanila_attn_mnli'\n",
    "custom_attention = False\n",
    "log_dir = './logs'\n",
    "checkpoints_dir = './runs'\n",
    "task = 'mnli'\n",
    "lr = 4e-5\n",
    "min_lr = 1e-6\n",
    "warmup_epochs = 0.5\n",
    "lr_decay_epochs = 3.5\n",
    "num_cpu = 16\n",
    "batch_size = 40\n",
    "grad_acc_steps = 1\n",
    "eval_acc_steps = 250\n",
    "log_per_steps = 100\n",
    "eval_per_steps = 1000\n",
    "save_per_steps = 1000\n",
    "weight_decay = 0.01\n",
    "no_progress_stop = 5\n",
    "checkpoint_path = None\n",
    "seed = 42\n",
    "num_gpu = sum([1 if x else 0 for x in CUDA_VISIBLE.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463927f4-3a38-428b-a2dc-249bf730ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(checkpoints_dir, experiment_name)\n",
    "logging_dir = os.path.join(log_dir, experiment_name)\n",
    "best_models_store_dir = os.path.join('./best_models', experiment_name)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "        \n",
    "if not os.path.exists(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "    \n",
    "if not os.path.exists(best_models_store_dir):\n",
    "    os.makedirs(best_models_store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e0b6cf-f972-4bd1-885b-ba3e9e5722ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, EarlyStoppingCallback, set_seed, \\\n",
    "                        TrainingArguments, Trainer, AdamW, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "from model import get_model, MODEL_NAME\n",
    "from data import get_processed_dataset, change_labels\n",
    "from utils import compute_metrics, save_labels_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb160ce-a9dd-4451-aa98-82ab3439aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "set_seed(seed)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5aaaf11-cf26-438c-abcf-5882d73b1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added logging\n",
    "\n",
    "file_formatter = logging.Formatter(fmt=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "                                       datefmt=\"%m/%d/%Y %H:%M:%S\", )\n",
    "file_handler = logging.FileHandler(\n",
    "    os.path.join(logging_dir, f\"log.{os.getpid()}.txt\"))\n",
    "file_handler.setFormatter(file_formatter)\n",
    "logging.root.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982d9ada-9e0a-417e-9482-fa65f8d41e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530a5ebe480f4e0aadde654f1240f6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if checkpoint_path:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(best_models_store_dir)\n",
    "    model = get_model(custom_attention=custom_attention,\n",
    "                      glue_task=task,\n",
    "                      path=checkpoint_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = get_model(custom_attention=custom_attention,\n",
    "                      glue_task=task)\n",
    "dataset = get_processed_dataset(tokenizer, task, seed)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "if task == \"mnli\":\n",
    "    val_data = concatenate_datasets([dataset[\"validation_matched\"], dataset[\"validation_mismatched\"]])\n",
    "    test_data = DatasetDict({'matched': dataset[\"test_matched\"].map(lambda x: change_labels(x)),\n",
    "                            'mismatched': dataset[\"test_mismatched\"].map(lambda x: change_labels(x))\n",
    "    })\n",
    "else:\n",
    "    val_data = dataset[\"validation\"]\n",
    "    test_data = dataset[\"test\"].map(lambda x: change_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad70e84-0512-4f6d-b02a-5e01d0bafde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_batch = batch_size * num_gpu * grad_acc_steps\n",
    "step_size = batch_size * grad_acc_steps\n",
    "warmup_steps = len(train_data) * warmup_epochs // step_size\n",
    "decay_steps = len(train_data) * lr_decay_epochs // step_size\n",
    "cos_cycles = np.arccos(min_lr/ lr) / np.pi\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, no_deprecation_warning=True)\n",
    "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, warmup_steps, decay_steps, cos_cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf2e09-f17d-438e-9769-219b8adde636",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667a76f2-9c6f-42b6-b305-9d1a885f4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_acc_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=np.ceil(warmup_epochs + lr_decay_epochs),\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_per_steps,\n",
    "    eval_accumulation_steps=eval_acc_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_per_steps,\n",
    "    save_total_limit=5,\n",
    "    logging_strategy =\"steps\",\n",
    "    logging_steps=log_per_steps,\n",
    "    dataloader_num_workers=num_cpu,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=no_progress_stop)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b7b397-968d-4b70-8a7d-cc02902d538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23000' max='39272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23000/39272 48:58 < 34:39, 7.83 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>0.631562</td>\n",
       "      <td>0.736092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.518636</td>\n",
       "      <td>0.795389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.482763</td>\n",
       "      <td>0.810251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>0.481939</td>\n",
       "      <td>0.815697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.543800</td>\n",
       "      <td>0.491543</td>\n",
       "      <td>0.817275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.504800</td>\n",
       "      <td>0.453921</td>\n",
       "      <td>0.830101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.442716</td>\n",
       "      <td>0.832901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.435667</td>\n",
       "      <td>0.835751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>0.433115</td>\n",
       "      <td>0.838194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.455467</td>\n",
       "      <td>0.837227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.440731</td>\n",
       "      <td>0.844098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.423140</td>\n",
       "      <td>0.845931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.476664</td>\n",
       "      <td>0.842317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.449721</td>\n",
       "      <td>0.836769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>0.469189</td>\n",
       "      <td>0.839314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.415920</td>\n",
       "      <td>0.846287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.410486</td>\n",
       "      <td>0.849850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.402620</td>\n",
       "      <td>0.846440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.409286</td>\n",
       "      <td>0.851988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>0.464520</td>\n",
       "      <td>0.841452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.469728</td>\n",
       "      <td>0.840586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.481892</td>\n",
       "      <td>0.850715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.445386</td>\n",
       "      <td>0.846898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23000, training_loss=0.4633067027382229, metrics={'train_runtime': 2940.9591, 'train_samples_per_second': 534.114, 'train_steps_per_second': 13.353, 'total_flos': 5.528273905454573e+16, 'train_loss': 0.4633067027382229, 'epoch': 2.34})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6406ddbe-c36c-4812-9bd8-36f9c10b4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(best_models_store_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739d577-cb10-4194-b6a8-d96c27832ad2",
   "metadata": {},
   "source": [
    "# INFERENCE\n",
    "### If not runned consequently with training rerun cells above training to initialize all required variables and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1dd4dc8-76c5-438d-9808-6e997bae52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(best_models_store_dir)\n",
    "model = get_model(custom_attention=custom_attention,\n",
    "                  glue_task=task,\n",
    "                  path=best_models_store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be01842f-664a-4d1e-81f8-2e748c9f3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir = \"evals\",\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    eval_accumulation_steps = eval_acc_steps,\n",
    "    dataloader_drop_last = False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    args = test_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda17fba-e6cd-413a-855c-044c7839279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added at the last moment since huggingface test mnli dataset not equal to real mnli test\n",
    "\n",
    "import pandas as pd    \n",
    "from datasets import Dataset\n",
    "from data import tokenize\n",
    "\n",
    "drop_columns=[\"annotator_labels\", \"genre\", \"gold_label\", \"promptID\", \"sentence1_binary_parse\",\n",
    "              \"sentence1_parse\", \"sentence2_binary_parse\", \"sentence2_parse\"]\n",
    "rename_map = {\"pairID\": \"idx\", \"sentence1\": \"premise\", \"sentence2\": \"hypothesis\"}\n",
    "\n",
    "def get_test_data_mnli(matched=True):\n",
    "    if matched:\n",
    "        f_name = 'multinli_0.9_test_matched_unlabeled.jsonl'\n",
    "    else:\n",
    "        f_name = 'multinli_0.9_test_mismatched_unlabeled.jsonl'\n",
    "        \n",
    "    with open(f_name, 'r') as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "    df = df.drop(drop_columns, axis=1)\n",
    "    df = df.rename(columns=rename_map)\n",
    "    df[\"label\"] = 0\n",
    "    data_dict = df.to_dict(orient='list')\n",
    "    dataset = Dataset.from_dict(data_dict)\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenize(\"mnli\", tokenizer, x), batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58fdf50b-9c0c-4d85-bd8a-b30102f64480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapping = {ix: val for ix, val in enumerate(dataset[\"train\"].features[\"label\"]._int2str)}\n",
    "\n",
    "if task == \"mnli\":\n",
    "    test_data_matched = get_test_data_mnli(matched=True)\n",
    "    raw_matched = trainer.predict(test_data_matched)\n",
    "    predictions_matched = np.argmax(raw_matched[0][0], axis=1)\n",
    "    idx_matched = []\n",
    "    for example in test_data_matched:\n",
    "        idx_matched.append(example[\"idx\"])\n",
    "    idx_matched = np.array(idx_matched)\n",
    "    test_data_mismatched = get_test_data_mnli(matched=False)\n",
    "    raw_mismatched = trainer.predict(test_data_mismatched)\n",
    "    predictions_mismatched = np.argmax(raw_mismatched[0][0], axis=1)\n",
    "    idx_mismatched = []\n",
    "    for example in test_data_mismatched:\n",
    "        idx_mismatched.append(example[\"idx\"])\n",
    "    idx_mismatched = np.array(idx_mismatched)\n",
    "    sps = (raw_matched[2]['test_samples_per_second'] + raw_mismatched[2]['test_samples_per_second']) / 2\n",
    "    save_labels_to_csv(idx_matched, predictions_matched, mapping, experiment_name + \"_matched.csv\")\n",
    "    save_labels_to_csv(idx_mismatched, predictions_mismatched, mapping, experiment_name + \"_mismatched.csv\")\n",
    "else:\n",
    "    raw_predicts = trainer.predict(test_data)\n",
    "    predictions = np.argmax(raw_predicts[0][0], axis=1)\n",
    "    idx = []\n",
    "    for example in test_data:\n",
    "        idx.append(example[\"idx\"])\n",
    "    sps = raw_predicts[2]['test_samples_per_second']\n",
    "    save_labels_to_csv(idx, predictions, mapping, experiment_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a758f2-33f7-4aa3-b27d-4042ee62805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449.29650000000004\n"
     ]
    }
   ],
   "source": [
    "# samples per second\n",
    "print(sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba9d65-2905-40eb-8690-405a96e87ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart",
   "language": "python",
   "name": "bart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
