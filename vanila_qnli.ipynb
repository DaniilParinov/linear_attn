{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae0c669-e177-4c86-9b9e-aa0f11902d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "CUDA_VISIBLE = '5'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00975a82-ca8c-4f67-bfa8-3c4771b80039",
   "metadata": {},
   "source": [
    "### Training params, you descriptions allows to not make cli and use notebook so I used it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b37a23-646f-45b2-ac8b-7dbb3dc507e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vanila_attn_qnli_llr'\n",
    "custom_attention = False\n",
    "log_dir = './logs'\n",
    "checkpoints_dir = './runs'\n",
    "task = 'qnli'\n",
    "lr = 2e-5\n",
    "min_lr = 1e-6\n",
    "warmup_epochs = 1\n",
    "lr_decay_epochs = 3\n",
    "num_cpu = 16\n",
    "batch_size = 24\n",
    "grad_acc_steps = 2\n",
    "eval_acc_steps = 250\n",
    "log_per_steps = 50\n",
    "eval_per_steps = 250\n",
    "save_per_steps = 250\n",
    "weight_decay = 0.01\n",
    "no_progress_stop = 5\n",
    "checkpoint_path = None\n",
    "seed = 42\n",
    "num_gpu = sum([1 if x else 0 for x in CUDA_VISIBLE.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463927f4-3a38-428b-a2dc-249bf730ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(checkpoints_dir, experiment_name)\n",
    "logging_dir = os.path.join(log_dir, experiment_name)\n",
    "best_models_store_dir = os.path.join('./best_models', experiment_name)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "        \n",
    "if not os.path.exists(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "    \n",
    "if not os.path.exists(best_models_store_dir):\n",
    "    os.makedirs(best_models_store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e0b6cf-f972-4bd1-885b-ba3e9e5722ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, EarlyStoppingCallback, set_seed, \\\n",
    "                        TrainingArguments, Trainer, AdamW, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "from model import get_model, MODEL_NAME\n",
    "from data import get_processed_dataset, change_labels\n",
    "from utils import compute_metrics, save_labels_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb160ce-a9dd-4451-aa98-82ab3439aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "set_seed(seed)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5aaaf11-cf26-438c-abcf-5882d73b1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#added logging\n",
    "\n",
    "file_formatter = logging.Formatter(fmt=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "                                       datefmt=\"%m/%d/%Y %H:%M:%S\", )\n",
    "file_handler = logging.FileHandler(\n",
    "    os.path.join(logging_dir, f\"log.{os.getpid()}.txt\"))\n",
    "file_handler.setFormatter(file_formatter)\n",
    "logging.root.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982d9ada-9e0a-417e-9482-fa65f8d41e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8fda5d90849fdb12b2c030cf6788f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if checkpoint_path:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(best_models_store_dir)\n",
    "    model = get_model(custom_attention=custom_attention,\n",
    "                      glue_task=task,\n",
    "                      path=checkpoint_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = get_model(custom_attention=custom_attention,\n",
    "                      glue_task=task)\n",
    "dataset = get_processed_dataset(tokenizer, task, seed)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "if task == \"mnli\":\n",
    "    val_data = concatenate_datasets([dataset[\"validation_matched\"], dataset[\"validation_mismatched\"]])\n",
    "    test_data = DatasetDict({'matched': dataset[\"test_matched\"].map(lambda x: change_labels(x)),\n",
    "                            'mismatched': dataset[\"test_mismatched\"].map(lambda x: change_labels(x))\n",
    "    })\n",
    "else:\n",
    "    val_data = dataset[\"validation\"]\n",
    "    test_data = dataset[\"test\"].map(lambda x: change_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad70e84-0512-4f6d-b02a-5e01d0bafde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_batch = batch_size * num_gpu * grad_acc_steps\n",
    "step_size = batch_size * grad_acc_steps\n",
    "warmup_steps = len(train_data) * warmup_epochs // step_size\n",
    "decay_steps = len(train_data) * lr_decay_epochs // step_size\n",
    "cos_cycles = np.arccos(min_lr/ lr) / np.pi\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, no_deprecation_warning=True)\n",
    "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, warmup_steps, decay_steps, cos_cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf2e09-f17d-438e-9769-219b8adde636",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667a76f2-9c6f-42b6-b305-9d1a885f4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir=logging_dir,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_acc_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=np.ceil(warmup_epochs + lr_decay_epochs),\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_per_steps,\n",
    "    eval_accumulation_steps=eval_acc_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_per_steps,\n",
    "    save_total_limit=5,\n",
    "    logging_strategy =\"steps\",\n",
    "    logging_steps=log_per_steps,\n",
    "    dataloader_num_workers=num_cpu,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=no_progress_stop)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b7b397-968d-4b70-8a7d-cc02902d538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5500' max='8728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5500/8728 16:33 < 09:43, 5.53 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.671255</td>\n",
       "      <td>0.593630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.430582</td>\n",
       "      <td>0.813472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.367797</td>\n",
       "      <td>0.845506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.332930</td>\n",
       "      <td>0.861981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.297057</td>\n",
       "      <td>0.873330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.371716</td>\n",
       "      <td>0.844408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.270489</td>\n",
       "      <td>0.887974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.259807</td>\n",
       "      <td>0.891269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.266347</td>\n",
       "      <td>0.895845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.288913</td>\n",
       "      <td>0.881933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.247457</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.899323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>0.909573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>0.911404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.268986</td>\n",
       "      <td>0.891818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.235875</td>\n",
       "      <td>0.911953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.216880</td>\n",
       "      <td>0.915431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.251783</td>\n",
       "      <td>0.914882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>0.235825</td>\n",
       "      <td>0.913051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.235471</td>\n",
       "      <td>0.915797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.223945</td>\n",
       "      <td>0.917811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.220877</td>\n",
       "      <td>0.918177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5500, training_loss=0.33325338658419523, metrics={'train_runtime': 995.5494, 'train_samples_per_second': 420.845, 'train_steps_per_second': 8.767, 'total_flos': 1.61226686625816e+16, 'train_loss': 0.33325338658419523, 'epoch': 2.52})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6406ddbe-c36c-4812-9bd8-36f9c10b4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(best_models_store_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739d577-cb10-4194-b6a8-d96c27832ad2",
   "metadata": {},
   "source": [
    "# INFERENCE\n",
    "### If not runned consequently with training rerun cells above training to initialize all required variables and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1dd4dc8-76c5-438d-9808-6e997bae52cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'ENTAILMENT', '1': 'NOT_ENTAILMENT'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(best_models_store_dir)\n",
    "model = get_model(custom_attention=custom_attention,\n",
    "                  glue_task=task,\n",
    "                  path=best_models_store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be01842f-664a-4d1e-81f8-2e748c9f3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir = \"evals\",\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    eval_accumulation_steps = eval_acc_steps,\n",
    "    dataloader_drop_last = False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    args = test_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58fdf50b-9c0c-4d85-bd8a-b30102f64480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapping = {ix: val for ix, val in enumerate(dataset[\"train\"].features[\"label\"]._int2str)}\n",
    "\n",
    "if task == \"mnli\":\n",
    "    raw_matched = trainer.predict(test_data[\"matched\"])\n",
    "    predictions_matched = np.argmax(raw_matched[0][0], axis=1)\n",
    "    idx_matched = []\n",
    "    for example in test_data[\"matched\"]:\n",
    "        idx_matched.append(example[\"idx\"])\n",
    "    idx_matched = np.array(idx_matched)\n",
    "    raw_mismatched = trainer.predict(test_data[\"mismatched\"])\n",
    "    predictions_mismatched = np.argmax(raw_mismatched[0][0], axis=1)\n",
    "    idx_mismatched = []\n",
    "    for example in test_data[\"mismatched\"]:\n",
    "        idx_mismatched.append(example[\"idx\"])\n",
    "    idx_mismatched = np.array(idx_mismatched)\n",
    "    sps = (raw_matched[2]['test_samples_per_second'] + raw_mismatched[2]['test_samples_per_second']) / 2\n",
    "    save_labels_to_csv(idx_matched, predictions_matched, mapping, experiment_name + \"_matched.csv\")\n",
    "    save_labels_to_csv(idx_mismatched, predictions_mismatched, mapping, experiment_name + \"_mismatched.csv\")\n",
    "else:\n",
    "    raw_predicts = trainer.predict(test_data)\n",
    "    predictions = np.argmax(raw_predicts[0][0], axis=1)\n",
    "    idx = []\n",
    "    for example in test_data:\n",
    "        idx.append(example[\"idx\"])\n",
    "    sps = raw_predicts[2]['test_samples_per_second']\n",
    "    save_labels_to_csv(idx, predictions, mapping, experiment_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72a758f2-33f7-4aa3-b27d-4042ee62805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457.488\n"
     ]
    }
   ],
   "source": [
    "# samples per second\n",
    "print(sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba9d65-2905-40eb-8690-405a96e87ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart",
   "language": "python",
   "name": "bart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
